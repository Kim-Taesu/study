#### 스파크 애플리케이션 아키텍처

- 스파크 드라이버
- 스파크 익스큐터
- 클러스터 매니저

#### 스파크 드라이버

- 스파크 애플리케이션의 `운전자 역할`을 하는 프로세스
- 스파크 애플리케이션의 실행을 제어하고 스파크 클러스터(익스큐터의 상태와 태스크)의 모든 상태 정보를 유지
- 물리적 컴퓨팅 자원 확보와 익스큐터 실행을 위해 클러스터 매니저와 통신할 수 있어야 한다.
  - 물리적 머신의 프로세스
  - 클러스터에서 실행 중인 애플리케이션의 상태를 유지

#### 스파크 익스큐터

- 스파크 드라이버가 할당한 태스크를 수행하는 프로세스
- 익스큐터는 드라이버가 할당한 태스크를 받아 실행하고 태스크의 상태와 결과를 드라이버에 보고
- 모든 스파크 애플리케이션은 개별 익스큐터 프로세스를 사용한다.

#### 클러스터 매니저

- 스파크 애플리케이션을 실행할 클러스터 머신을 유지
- 클러스터 매니저도 `드라이버(master)`와 `워커(worker)` 라는 개념이 있다.
  - 프로세스가 아닌 물리적인 머신에 연결되는 개념이다.
- 스파크가 지원하는 클러스터 매니저
  - standalone
  - Apache Mesos
  - Hadoop YARN

---

#### 스파크 애플리케이션 실행

- `spark-submit` 명령어 사용
- 클러스터 매니저에 자원 할당을 요청
- 사용자 애플리케이션의 설정에 따라
  - 스파크 드라이버를 실행할 자원을 포함해 요청
  - 스파크 애플리케이션 실행을 위한 익스큐터 자원을 요청
- 스파크 애플리케이션 실행 과정에서 클러스터 매니저는 애플리케이션이 실행되는 머신을 관리

---

#### 실행 모드

- 클러스터 모드
- 클라이언트 모드
- 로컬 모드

#### 클러스터 모드

- 컴파일된 JAR 파일이나 파이썬 스크립트 또는 R 스크립트를 클러스터 매니저에 전달해야 한다.
- 클러스터 매니저는 파일을 받고 워커 노드에 드라이버와 익스큐터 프로세스를 실행
  - 클러스터 매니저는 모든 스파크 애플리케이션과 관련된 프로세스를 유지하는 역할
- 하나의 워커 노드에 스파크 드라이버를 할당하고 다른 워커 노드에 익스큐터를 할당한다.

![Spark cluster components](https://spark.apache.org/docs/latest/img/cluster-overview.png)

#### 클라이언트 모드

- 애플리케이션을 제출한 클라이언트 머신에 스파크 드라이버가 위치한다
- 클라이언트 머신은 스파크 드라이버 프로세스를 유지하며 클러스터 매니저는 익스큐터 프로세스를 유지
- 스파크 애플리케이션이 클러스터와 무관한 머신에서 동작한다.
  - 이 때 클라이언트 머신을 `게이트웨이 머신` 또는 `에지 노드`라고 한다.
- 스파크 드라이버는 클러스터 외부의 머신에서 실행되며 나머지 워커는 클러스터에 위치

---

## 스파크 애플리케이션의 생애 주기 (스파크 외부)

#### 클라이언트 요청

1. 스파크 애플리케이션 제출

   - 스파크 애플리케이션 : 컴파일된 JAR나 라이브러리 파일
   - `spark-submit`으로 제출

2. 제출하는 시점에 로컬 머신에서 코드가 실행되어 클러스터 드라이버 노드에 요청

   - 스파크 드라이버 프로세스의 자원을 함께 요청

3. 클러스터 매니저는 요청을  받아들이고 클러스터 노드 중 하나에 드라이버 프로세스 실행

4. 스파크 잡을 제출한 클라이언트 프로세스는 종료되고 애플리케이션은 클러스터에서 실행

   ```shell
   ./bin/spark-submit \
   --class <main-class> \
   --master <master-url> \
   --deploy-mode cluster \
   --conf <key>=<value> \
   <application.jar> \
   [application-arguments]
   ```

#### 시작

- 드라이버 프로세스가 클러스터에 배치되었으므로 사용자 코드를 실행
  - 사용자 코드에는 반드시 스파크 클러스터를 초기화하는 SparkSession이 포함되어야 한다.
  - SparkSession은 클러스터 매니저와 통신해 스파크 익스큐터 프로세스의 실행을 요청한다.
- 클러스터 매니저는 익스큐터 프로세스를 시작하고 결과를 응답받아 익스큐터의 위치와 관련 정보를 드라이버 프로세스로 전송한다.
- 위 작업이 끝나면 `스파크 클러스터`가 완성

#### 실행

- `스파크 클러스터`가 생성된 것을 확인하면 코드를 실행한다.
- 스파크 드라이버와 스파크 워커는 코드를 실행하고 데이터를 이동하는 과정에서 서로 통신 한다.
  - 드라이버는 워커에게 태스크를 할당
  - 태스크를 할당받은 워커는 태스크의 상태와 성공/실패 여부를 드라이버에 전송

#### 완료

- 스파크 애플리케이션 실행이 완료되면 드라이버 프로세스가 성공이나 실패 중 하나의 상태로 종료
- 클러스터 매니저는 드라이버가 속한 스파크 클러스터의 모든 익스큐터를 종료한다.

---

## 스파크 애플리케이션의 생애주기 (스파크 내부)

#### 스파크 애플리케이션은 하나 이상의 스파크 잡으로 구성된다.

#### SparkSession

- 대화형 방식이 아니라면 직접 생성해야 한다.

  ```scala
  val spark = SparkSession.builder().appName("~~")
  	.config("spark.sql.warehouse.dir","warehouse_PATH")
  	.getOrCreate()
  ```

- SparkSession을 생성하면 스파크 코드를 실행할 수 있다.

  - 모든 저수준 API, 기존 컨텍스트 그리고 관련 설정 정보에 접근 가능

#### SparkContext

- RDD, 어큐뮬레이터, 브로드캐스트 변수를 생성하고 코드를 실행할 수 있다.
- 대부분의 경우 SparkSession으로 SparkContext에 접근 가능

#### 논리적 명령

- 액션을 호출하면 개별 `스테이지`와 `태스크`로 이루어진 스파크 `잡`이 실행된다.
  - `localhost:4040`에 접속하여 스파크 UI 확인 가능

***잡 > 스테이지 > 태스크***

#### 스파트 잡

- 보통 액션 하나당 하나의 스파크 잡이 생성
  - 액션은 항상 결과를 반환
- 스파크 잡은 일련의 스테이지로 나뉘며 스테이지 수는 ㅅ ㅕ플 작업이 얼마나 많이 발생하는지에 따라 달라진다.

#### 스테이지

- 다수의 머신에서 동일한 연산을 수행하는 태스크의 그룹을 나타낸다.
- 스파크는 가능한 한 많은 태스크(잡의 트랜스포메이션)를 동일한 스테이지로 묶으려 노력한다.
- 셔플 작업이 일어난 다음에는 반드시 새로운 스테이지를 시작한다.
  - 셔플은 데이터의 물리적 재분배 과정이다.
  - `spark.sql.shuffle.partitions`의 값을 설정하여 셔플 파티션 값을 설정한다.
  - 클러스터의 익스큐터 수보다 파티션 수를 더 크게 지정하는 것이 좋다.

#### 태스크

- 스파크 스테이지는 태스크로 구성된다.
- 각 태스크는 단일 익스큐터에서 실행할 데이터의 블록과 다수의 트랜스포메이션 조합으로 볼 수 있다.
- 만약 데이터셋이 거대한 하나의 파티션인 경우 하나의 태스크만 생성
- **데이터 단위(파티션)에 적용되는 연산 단위**
  - 파티션 수를 늘리면 더 높은 병렬성을 얻을 수 있다.

#### 파이프라이닝

- 스파크는 메모리나 디스크에 데이터를 쓰기 전에 최대한 많은 단계를 수행한다.
- 노드 간의 데이터 이동 없이 각 노드가 데이터를 직접 공급할 수 있는 연산만 모아 태스크의 단일 스테이지로 만드는 기법
- 파이프라인으로 구성된 연산 작업은 단계별로 메모리나 디스크에 중간 결과를 기록하는 방식보다 훨씬 더 처리 속도가 빠르다.
- 스파크 런타임에서 파이프라이닝을 자동으로 수행

#### 셔플 결과 저장

- 노드 간 복제를 유발하는 연산(reduce-by-key)을 실행하면 엔진에서 파이프라이닝을 수행하지 못하므로 네트워크 셔플이 발생
  - 노드 간 복제를 유발하는 연산은 각 키에 대한 입력 데이터를 먼저 여러 노드로부터 복사한다.
  - 항상 데이터 전송이 필요한 `소스` 태스크를 먼저 수행하기 때문
  - 소스 태스크의 스테이지가 실행되는 동안 셔플 파일을 로컬 디스크에 기록
  - 이후 그룹화나 리듀스를 수행하는 스테이지가 시작
- 이미 셔플된 데이터를 이용해 새로운 잡을 실행하면 `소스`와 관련된 셔플이 다시 실행되지 않는다.