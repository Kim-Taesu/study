#### 운영용 애플리케이션 실행

- spark-submit 명령을 사용해 대화형 쉘에서 개발한 프로그램을 운영용 애플리케이션으로 전환

  - spark-submit 명령으로 애플리케이션 코드를 클러스터에 전송해 실행
  - 클러스터에 제출된 애플리케이션은 작업이 종료되거나 에러가 발생할 때까지 실행

- 가장 간단한 방법은 로컬 머신에서 애플리케이션 실행

  ```shell
  spark-submit \
  	--class your.spark.class \
  	--master local \
  	spark_jar_path.jar argv...
  ```

#### Dataset

- 정적 데이터 타입에 맞는 코드, 정적 타입 코드를 지원하기 위해 고안된 스파크의 구조적 API

  - 정적 타입 코드 : 자료형이 고정된 언어 (자바, 스칼라, C, C++ 등)
  - 동적 타입 코드 : 파이썬, 자바스크립트

- 타입 안정성을 지원

- 다수의 소프트웨어 엔지니어가 잘 정의된 인터페이스로 상호작용하는 대규모 애플리케이션을 개발하는데 유용

- 타입 안정성 함수와 DataFrame을 사용해 비즈니스 로직을 신속하게 작성하는 예제

  ```scala
  import org.apache.spark.sql.SparkSession
  
  case class Flight(DEST_COUNTRY_NAME: String,
                    ORIGIN_COUNTRY_NAME: String,
                    count: BigInt)
  
  object Main {
    def main(args: Array[String]): Unit = {
  
      val spark = SparkSession.builder().master("local").appName("test").getOrCreate()
  
      import spark.implicits._
  
      val myrange = spark.range(1000).toDF("number")
  
  
      val flightsDF = spark.read
        .parquet("data/flight-data/parquet/2010-summary.parquet/")
      val flights = flightsDF.as[Flight]
    }
  }
  
  ```

  - collect, take 메서드를 호출하면 DataFrame을 구성하는 Row 타입의 객체가 아닌 Dataset에 매개변수로 지정한 타입의 객체를 반환
    - 타입 안정성 보장

#### 구조적 스트리밍

- 스파크 2.2 버전에서 안정화된 스트림 처리용 고수준 API
- 구조적 스트리밍을 사용하면 구조적 API로 개발된 배치 모드의 연산을 스트리밍 방식으로 실행 가능
- 배치 처리용 코드를 일부 수정하여 스트리밍 처리를 수행하고 값을 빠르게 얻을 수 있다